# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DZzTBi9W8BWFEpC1IG0FFU4ASD_LXM9c
"""

# streamlit_app.py

import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import torch

# --- SECTION 1: Load Datasets ---
@st.cache_data
def load_data():
    symptom_df = pd.read_csv("hpo_cleaned.csv").dropna(subset=["id", "name", "definition"])
    gene_df = pd.read_csv("orphanet_phenotype_to_genes.csv")
    rd_df = pd.read_csv("cleaned_rare_disabilities.csv")
    return symptom_df, gene_df, rd_df

symptom_df, gene_df, rd_df = load_data()

# --- SECTION 2: Preprocessing ---
hpo_symptoms = symptom_df["definition"].unique().tolist()
hpo_symptoms = [s.lower().strip() for s in hpo_symptoms]
model = SentenceTransformer('all-MiniLM-L6-v2')
hpo_embeddings = model.encode(hpo_symptoms, convert_to_tensor=True)

def extract_symptoms_from_text(text, threshold=0.6):
    input_embedding = model.encode(text, convert_to_tensor=True)
    cosine_scores = util.cos_sim(input_embedding, hpo_embeddings)[0]
    matches = [(hpo_symptoms[i], float(score)) for i, score in enumerate(cosine_scores) if score > threshold]
    matches.sort(key=lambda x: x[1], reverse=True)
    return matches

# --- Streamlit UI ---

st.title("üß¨ Rare Disease Predictor Using HPO Symptoms")

user_input = st.text_input("Enter symptoms (separated by commas):", placeholder="e.g., seizure, muscle weakness")

if user_input:
    input_texts = [s.strip() for s in user_input.split(",") if s.strip()]
    matched_hpo_sets = []
    hpo_details = {}

    st.subheader("üîç NLP Extracted Symptoms & HPO Matches")
    for text in input_texts:
        matches = extract_symptoms_from_text(text)
        top_matches = matches[:3]

        st.markdown(f"**For input:** _{text}_")
        if not top_matches:
            st.warning("No close symptoms found.")
            continue

        current_set = set()
        for label, score in top_matches:
            matched_rows = symptom_df[symptom_df["definition"].str.lower().str.strip() == label]
            for _, row in matched_rows.iterrows():
                hpo_id = row['id']
                name = row['name']
                current_set.add(hpo_id)
                hpo_details[hpo_id] = (name, score)
                st.write(f"- Symptom: **{name}** | HPO ID: `{hpo_id}` | Score: {score:.2f}")
        matched_hpo_sets.append(current_set)

    if matched_hpo_sets:
        common_hpo_ids = set.intersection(*matched_hpo_sets)
        if common_hpo_ids:
            st.subheader("üîó Common HPO Matches Across All Input Symptoms")
            for hpo_id in common_hpo_ids:
                name, score = hpo_details[hpo_id]
                st.write(f"- Symptom: **{name}** | HPO ID: `{hpo_id}` | Score: {score:.2f}")

            st.subheader("üß¨ Gene & Disease Info for Common HPO Terms")
            for hpo_id in common_hpo_ids:
                matches = gene_df[gene_df["hpo_id"] == hpo_id]
                if not matches.empty:
                    st.markdown(f"**HPO ID: {hpo_id} ‚Äî {hpo_details[hpo_id][0]}**")
                    for _, row in matches.iterrows():
                        st.write(f"   ‚û§ Gene: `{row['gene_symbol']}` | Disease ID: `{row['disease_id']}`")
        else:
            st.warning("No HPO terms matched all input symptoms.")

    # --- Rare Disease Prediction ---
    st.subheader("üèÜ Top 5 Matching Rare Diseases")
    unique_orpha_numbers = gene_df['disease_id'].str.extract(r'(\d+)')[0].unique()
    rd_df['OrphaCode'] = rd_df['OrphaCode'].astype(str)
    matched_df = rd_df[rd_df['OrphaCode'].isin(unique_orpha_numbers)]

    if matched_df.empty:
        st.warning("No diseases found for those ORPHA codes.")
    else:
        grouped_df = matched_df.groupby('OrphaCode').agg({
            'Frequency': lambda x: x.mode()[0],
            'Severity': lambda x: x.mode()[0],
            'DisabilityName': lambda x: list(x.unique()),
            'DisorderName': lambda x: x.iloc[0]
        }).reset_index()

        freq_order = {'very frequent': 1, 'frequent': 2, 'occasional': 3, 'rare': 4}
        severity_order = {'very severe': 1, 'severe': 2, 'moderate': 3, 'mild': 4}

        grouped_df['freq_rank'] = grouped_df['Frequency'].str.lower().map(freq_order)
        grouped_df['severity_rank'] = grouped_df['Severity'].str.lower().map(severity_order)

        top_results = grouped_df.sort_values(['freq_rank', 'severity_rank']).head(5)

        for _, row in top_results.iterrows():
            st.markdown(f"**üß¨ Disorder:** `{row['DisorderName']}` _(ORPHA:{row['OrphaCode']})_")
            st.write(f"   ‚û§ Frequency: {row['Frequency']}")
            st.write(f"   ‚û§ Severity: {row['Severity']}")
            st.write("   ‚û§ Symptoms:")
            for symptom in row['DisabilityName']:
                st.write(f"      ‚Ä¢ {symptom}")